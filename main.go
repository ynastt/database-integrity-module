package main

import (
	"flag"
	"fmt"
	"log"
	"strconv"
	"strings"
	"os"
	"encoding/hex"
	"encoding/json"
	driver "github.com/arangodb/go-driver"
	"github.com/arangodb/go-driver/http"
	"github.com/Toorop/go-bitcoind"
)

type Node struct {
	Key	string	`json:"_key"`
}

type Edge struct {
	Key		string	`json:"_key"`
	From		string	`json:"_from"`	
	To		string	`json:"_to"`
}

type BitcoinTxNode struct {
	Key	string	`json:"_key"`
	Time 	uint64	`json:"time"`
}

type BitcoinAddressNode struct {
	Key	string	`json:"_key"`
}

type BitcoinBlockNode struct {
	BlockHeight	int64 	`json:"blockHeight"` 
	Key		string	`json:"_key"`		//string(blockHeight)
	blockHash	string	`json: "blockHash"`
}

type BitcoinParentBlockEdge struct {
	Key		string	`json:"_key"`	
	From		string	`json:"_from"`	
	To		string	`json:"_to"`	
}

type BitcoinOutputEdge struct {
	Key		string	`json:"_key"`	// arango _key is generated by arango txId + '_' + outIndex
	From		string	`json:"_from"`	// arango id of transaction 'btcTx/{_key}'
	To		string	`json:"_to"`	// arango id of block 'btcAddress/{_key}'
	OutIndex	int	`json:"outIndex`
	SpentBtc	uint64	`json:"spentBtc"`
	Time 		uint64	`json:"time"`
}

type BitcoinNextEdge struct {
	Key		string	`json:"_key"`	// arango _key is generated by arango  txId + '_' + outIndex
	From		string	`json:"_from"`	// arango id of transaction 'btcTx/{_key}'
	To		string	`json:"_to"`	// arango id of block 'btcTx/{_key}'
	Address	string	`json:"address"`
	OutIndex	int 	`json:"outIndex`
	SpentBtc	uint64	`json:"spentBtc"`
}	

//BitcoinInEdge has the same structure as BitcoinOutputEdge but _from :'btcAddress/{_key}', _to: 'btcTx/{_key}'

const (
	SERVER_HOST        = "localhost"
	SERVER_PORT        = 10001
	USER               = "btcuser"
	PASSWD             = "1234"
	USESSL             = false
)

func main() {
	bc, err := bitcoind.New(SERVER_HOST, SERVER_PORT, USER, PASSWD, USESSL)
	if err != nil {
		log.Fatalln(err)
	}
	/* getblockcount */
	/*count, err := bc.GetBlockCount()
	if err != nil {
		log.Fatalf("Failed to get blockCount: %v", err)
	}
	log.Printf("Block count: %d", count) */
	
	/* for saving _key fields of docs for ImportDocuments method */
	arr_block := make([]Node, 0, 10000)	// capacity = 1000 or sth else (decide later)
	arr_tx := make([]Node, 0, 10000)	// capacity = 1000 or sth else (decide later)
	arr_addr := make([]Node, 0, 10000)	// capacity = 1000 or sth else (decide later)
	arr_in := make([]Edge, 0, 10000)	// capacity = 1000 or sth else (decide later)
	arr_out := make([]Edge, 0, 10000)	// capacity = 1000 or sth else (decide later)
	arr_next := make([]Edge, 0, 10000)	// capacity = 1000 or sth else (decide later)
	arr_parent := make([]Edge, 0, 10000)	// capacity = 1000 or sth else (decide later)	
	
	/* map for types of transactions type->seen/not (true, false)*/
	typesTx := map[string]bool { 		// has address field?
		"pubkeyhash": false,		// yes
		"nonstadard": false,		// no 
		"multisig": false,		// no 
		"pubkey": false,		// no 
		"scripthash" : false,		// yes
		"nulldata": false,		// no 
		"witness_v0_keyhash" : false,	// yes
		"witness_v0_scripthash": false,// yes
		"witness_unknown": false,	// no
	}
	
	/* counters for each type */
	pbkh := 0
	nstd := 0
	mltsg := 0
	pbk := 0
	srpth := 0
	nulld := 0
	w_kh := 0
	w_srpth := 0
	w_un := 0
	
	 /* file for transactions with special types in vout of tx and their tx_hash*/
	file, err := os.Create("transactions.txt")
    	if err != nil{
        	fmt.Println("Unable to create file:", err) 
        	os.Exit(1) 
    	}
    	defer file.Close() 
    	
   	 /* file for nodes and edges didn`t exist in db before importDocument method*/
	keys, err := os.Create("keys_of_imported_docs.txt")
    	if err != nil{
        	fmt.Println("Unable to create file:", err) 
        	os.Exit(1) 
    	}
    	defer keys.Close() 
    	
	
	var n uint64
	for n = 1; n < 207672; n ++ {
	
		/* get blockhash */
		hash, err := bc.GetBlockHash(n)
		if err != nil {
			log.Fatalf("Failed to get blockHash: %v", err)
		}
		//log.Printf("block %d has blockHash: %s", n, hash)
	
		/* get block */
		block, err := bc.GetBlock(hash)
		if err != nil {
			log.Fatalf("Failed to get blockBlock: %v", err)
		}
		//log.Printf("_key in btcBlock: %d", block.Height)
		str := strconv.FormatInt(int64(block.Height), 10)
		arr_block = append(arr_block, Node{ Key: str, })

	
		/* get all txid from msg_block */
		block_tx := block.Tx
		//for i, t := range block_tx {
		//	log.Printf("tx %d: %s", i, t)
		//}
		//log.Printf("tx`s of btcBlock: %s", msg_block.Tx)
	
	
		/* for each txid get the raw transaction */
		for _, t := range block_tx {
			msg_tx, err := bc.GetRawTransactionUPD(t, true)	// my method GetRawTransactionUPD I added to package
			if err != nil {
				log.Fatalf("Failed to get rawTransaction: %v", err)
			}
			//log.Printf("\n_key in btcTx: %s", msg_tx.Txid)
			arr_tx = append(arr_tx, Node{ Key: msg_tx.Txid, })
			parentBlockKey := str + "_" + msg_tx.Txid
			//log.Printf("_key in btcParentBlock: %s", parentBlockKey)
			arr_parent = append(arr_parent, Edge{ Key: parentBlockKey, From: "t/t", To: "t/t", })
		
			for _, vin := range msg_tx.Vin {
				txid := vin.Txid
				//log.Printf("txid field: %s", txid)
				vout := vin.Vout //int
				voutstr := strconv.Itoa(vout)
				//log.Printf("vout field: %s", voutstr)
				var edgesKey, edgeOutKey string
				if txid == "" && voutstr == "" {
					edgesKey = ""
					edgeOutKey = ""
				} else if txid == "" && voutstr != "" {
					edgesKey = ""
					edgeOutKey = msg_tx.Txid + "_" + voutstr
				} else {
					edgesKey = txid + "_" + voutstr
					edgeOutKey = txid + "_" + voutstr
				}
				//log.Printf("_key in btcIn: %s", edgesKey)
				//log.Printf("_key in btcOut: %s", edgeOutKey)
				//log.Printf("_key in btcNext: %s", edgesKey)
				if edgesKey != "" {
					arr_in = append(arr_in, Edge{ Key: edgesKey, From: "t/t", To: "t/t", })
					arr_out = append(arr_out, Edge{ Key: edgeOutKey, From: "t/t", To: "t/t", })
					arr_next = append(arr_next, Edge{ Key: edgesKey, From: "t/t", To: "t/t", })
				}
			}
			for _, vout := range msg_tx.Vout {
				address := vout.ScriptPubKey.Address
				index_of_tx_output := strconv.Itoa(vout.N)
				type_vout := vout.ScriptPubKey.Type
				//log.Printf("index of tx output: %s", index_of_tx_output)	
				var addrKey string
				if address == ""{
					addrKey = msg_tx.Txid + "_" + index_of_tx_output 
					//log.Printf("_key in btcAddress: %s", addrKey)
					if type_vout == "nonstadard" && typesTx["nonstadard"] == false {
						typesTx["nonstadard"] = true
						nstd++
						file.WriteString("nonstandard: " + msg_tx.Txid + "\n")
						if nstd < 10  {		
							typesTx["nonstadard"] = false
						}
					}
					if type_vout == "multisig" && typesTx["multisig"] == false {
						typesTx["multisig"] = true
						mltsg++
						file.WriteString("multisig: " + msg_tx.Txid + "\n")
						if mltsg < 10  {	
							typesTx["multisig"] = false
						}
					}
					if type_vout == "pubkey" && typesTx["pubkey"] == false {
						typesTx["pubkey"] = true
						pbk++
						file.WriteString("pubkey: " + msg_tx.Txid + "\n")
						if pbk < 10  {	
							typesTx["pubkey"] = false
						}
					}
					if type_vout == "nulldata" && typesTx["nulldata"] == false {
						typesTx["nulldata"] = true
						nulld++
						file.WriteString("nulldata: " + msg_tx.Txid + "\n")
						if nulld < 10  {	
							typesTx["nulldata"] = false
						}
					}
					if type_vout == "witness_unknown" && typesTx["witness_unknown"] == false {
						typesTx["witness_unknown"] = true
						w_un++
						file.WriteString("witness_unknown: " + msg_tx.Txid + "\n")
						if w_un< 10  {	
							typesTx["witness_unknown"] = false
						}
					}
				} else {
					addrKey = address
					//log.Printf("_key in btcAddress: %s", address)
					if type_vout == "pubkeyhash" && typesTx["pubkeyhash"] == false {
						typesTx["pubkeyhash"] = true
						pbkh++
						file.WriteString("pubkeyhash: " + msg_tx.Txid + "\n")
						if pbkh < 10  {		
							typesTx["pubkeyhash"] = false
						}
					}
					if type_vout == "scripthash" && typesTx["scripthash"] == false {
						typesTx["scripthash"] = true
						srpth++
						file.WriteString("scripthash: " + msg_tx.Txid + "\n")
						if srpth < 10  {		
							typesTx["scripthash"] = false
						}
					}
					if type_vout == "witness_v0_keyhash" && typesTx["witness_v0_keyhash"] == false {
						typesTx["witness_v0_keyhash"] = true
						w_kh++
						file.WriteString("witness_v0_keyhash: " + msg_tx.Txid + "\n")
						if w_kh < 10  {		
							typesTx["witness_v0_keyhash"] = false
						}
					}
					if type_vout == "witness_v0_scripthash" && typesTx["witness_v0_scripthash"] == false {
						typesTx["witness_v0_scripthash"] = true
						w_srpth++
						file.WriteString("witness_v0_scripthash: " + msg_tx.Txid + "\n")
						if w_srpth < 10  {		
							typesTx["witness_v0_scripthash"] = false
						}
					}
				}	
				arr_addr = append(arr_addr, Node{ Key: addrKey, })
			}
		}
	
	
		/* connect to arangodb server using http */
		var client driver.Client
		var conn driver.Connection
	
		flag.Parse()

		conn, err = http.NewConnection(http.ConnectionConfig{
			Endpoints: []string{"http://localhost:8529"},
		})
		if err != nil {
			log.Fatalf("Failed to create HTTP connection: %v", err)
		}
		client, err = driver.NewClient(driver.ClientConfig{
			Connection:     conn,
			Authentication: driver.BasicAuthentication("root", ""),
		})
	
		var db driver.Database
		var db_exists bool
	
		/* open database */
		db_name := "mybd"
		db_exists, err = client.DatabaseExists(nil, db_name)
	
		if db_exists {
			db, err = client.Database(nil, db_name)
			if err != nil {
				log.Fatalf("Failed to open existing database: %v", err)
			} 
			fmt.Println("\n" + db.Name() + " exists")
		} else {
			db, err = client.CreateDatabase(nil, db_name, nil)
			if err != nil {
				log.Fatalf("Failed to create database: %v", err)
			}
		}
	
		/* use importDocuments method for each collection*/
		log.Println("import docs start here")
	//arr_in = append(arr_in, Edge{ Key: "blablabla", From: "t/t", To: "t/t", })
	//log.Println("arr_in:")
	//log.Println(arr_in)
		ImportNodes(db, "btcBlock", arr_block, keys)
		ImportNodes(db, "btcTx", arr_tx, keys)
		ImportNodes(db, "btcAddress", arr_addr, keys)
		ImportEdges(db, "btcIn", arr_in, keys)
		ImportEdges(db, "btcOut", arr_out, keys)
		ImportEdges(db, "btcNext", arr_next, keys)
		ImportEdges(db, "btcParentBlock", arr_parent, keys)	
	}
}


/* ====================== helpful functions ====================== */
func formatRawResponse(raw []byte) string {
	l := len(raw)
	if l < 2 {
		return hex.EncodeToString(raw)
	}
	if (raw[0] == '{' && raw[l-1] == '}') || (raw[0] == '[' && raw[l-1] == ']') {
		return string(raw)
	}
	return hex.EncodeToString(raw)
}

func describe(err error) string {
	if err == nil {
		return "nil"
	}
	cause := driver.Cause(err)
	var msg string
	if re, ok := cause.(*driver.ResponseError); ok {
		msg = re.Error()
	} else {
		c, _ := json.Marshal(cause)
		msg = string(c)
	}
	if cause.Error() != err.Error() {
		return fmt.Sprintf("%v caused by %v (%v)", err, cause, msg)
	}
	return fmt.Sprintf("%v (%v)", err, msg)
}

func ImportNodes(db driver.Database, coll string, arr []Node, keys *os.File) {
	c, err := db.Collection(nil, coll)
	if err != nil {
		log.Fatalf("Failed openning the collection: %v", err)
	}
	var raw []byte
	var details []string
	ctx := driver.WithImportDetails(driver.WithRawResponse(nil, &raw), &details)
	var options driver.ImportDocumentOptions
	options = driver.ImportDocumentOptions{ Overwrite: false, OnDuplicate: "ImportOnDuplicateError", Complete: false,}
	stats, err := c.ImportDocuments(ctx, arr, &options)
	if err != nil {
		log.Fatalf("Failed to import documents: %s %#v", describe(err), err)
	} else {
		if stats.Created != int64(len(arr)) {
			log.Printf("Expected %d created documents, got %d (json %s)", len(arr), stats.Created, formatRawResponse(raw))
			// field Created holds the number of documents imported.
			// we expect that method ImportDocuments will import all docs from array. 
			//But this method will not import the current document because of the unique key constraint violation.

			details_str := strings.Join(details, " ")
			for _, a := range arr {
				if !strings.Contains(details_str, a.Key) {
					keys.WriteString("collection: " + coll + ", _key: " + a.Key + "\n")
				}		
			}	
		}
	}	
}

func ImportEdges(db driver.Database, coll string, arr []Edge, keys *os.File) {
	c, err := db.Collection(nil, coll)
	if err != nil {
		log.Fatalf("Failed openning the collection: %v", err)
	}
	var raw []byte
	var details []string
	ctx := driver.WithImportDetails(driver.WithRawResponse(nil, &raw), &details)
	var options driver.ImportDocumentOptions
	options = driver.ImportDocumentOptions{ Overwrite: false, OnDuplicate: "ImportOnDuplicateError", Complete: false,}
	stats, err := c.ImportDocuments(ctx, arr, &options)
	if err != nil {
		log.Fatalf("Failed to import documents: %s %#v", describe(err), err)
	} else {
		if stats.Created != int64(len(arr)) {
			log.Printf("Expected %d created documents, got %d (json %s)", len(arr), stats.Created, formatRawResponse(raw))
			// field Created holds the number of documents imported.
			// we expect that method ImportDocuments will import all docs from array. 
			//But this method will not import the current document because of the unique key constraint violation.

			details_str := strings.Join(details, " ")
			for _, a := range arr {
				if !strings.Contains(details_str, a.Key) {
					keys.WriteString("collection: " + coll + ", _key: " + a.Key + "\n")
				}		
			}
			
		}
	}	
}

//TODO
// каналы для коллекций чтобы разделить чтение и с биткоина и запись в аранго 
// распараллелить блоки?
// отдельный скрипт на основе этого для проверки по всем полям для коллекций 
// гит 
